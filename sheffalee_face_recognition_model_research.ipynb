{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task 5 : Facial Recognition Model Research\n",
        "\n",
        "Model 1:  FaceNet\n",
        "\n",
        "FaceNet is a pioneering deep learning model developed by Google for face recognition. It revolutionized the field by learning to map faces into a high-dimensional space where similar faces are located close together. It uses a triplet loss function to train, encouraging faces of the same identity to be close while pushing faces of different individuals apart. FaceNet's embeddings are highly discriminative, enabling precise face verification and recognition. Its remarkable accuracy and robustness to pose, lighting, and expression variations have made it a foundation for various facial analysis applications, including security, authentication, and personalization.\n",
        "\n",
        "Model 2:  DeepFace\n",
        "\n",
        "DeepFace is a pioneering facial recognition model developed by Facebook AI Research in 2014. It employs a deep convolutional neural network (CNN) architecture, excelling in face verification, the process of confirming if two images depict the same person. DeepFace learns rich facial features and computes similarity scores between face representations. With impressive accuracy, it competes with human-level performance and remains resilient to variations in facial expressions, poses, and lighting conditions. Although not designed for real-time applications, its innovations have significantly contributed to the field of facial recognition, making it an influential milestone in the development of this technology.\n",
        "\n",
        "Model 3:  VGG-Face\n",
        "\n",
        "The VGG-Face model is a convolutional neural network (CNN) architecture specifically designed for face recognition. Based on the popular VGGNet architecture, it was fine-tuned using a massive dataset containing images of thousands of celebrities' faces. VGG-Face excels in the task of face recognition, offering highly accurate results due to its ability to capture intricate facial features.\n",
        "\n",
        "Its deep layers enable it to learn hierarchical representations of faces, making it robust to variations in pose, expression, and lighting conditions. This model has been widely adopted in academic and industry applications, particularly for recognizing celebrity faces in images and videos. Its simplicity, combined with its remarkable performance, has cemented VGG-Face's place as a significant contribution to the field of facial recognition.\n",
        "\n",
        "Model 4:  MTCNN\n",
        "\n",
        "MTCNN (Multi-task Cascaded Convolutional Networks), is a deep learning model widely used for face detection. Comprising three cascaded networks, MTCNN sequentially identifies faces within an image. The first network proposes potential face regions, the second one refines these proposals, and the third performs facial landmark detection. MTCNN is highly effective in detecting faces accurately, even in challenging scenarios with varying sizes, poses, and illuminations. Its efficiency and precision make it a popular choice for real-time applications like facial recognition, emotion analysis, and age estimation, contributing significantly to the success of face-related tasks in computer vision and machine learning.\n",
        "\n",
        "Model 5:  ArcFace\n",
        "\n",
        "ArcFace is a state-of-the-art face recognition model that enhances facial feature embeddings for accurate and discriminative recognition. It introduces the concept of angular margin loss during training, which optimizes the embeddings to have larger angular differences between faces of different identities while pulling those of the same identity closer. This results in highly effective and distinct face representations, making ArcFace one of the most accurate models for face recognition tasks. It excels in scenarios with large-scale datasets, robustly handling variations in lighting, pose, and expression. ArcFace has applications in security, surveillance, and identity verification, where precision and reliability are crucial.\n",
        "\n",
        "Among the above mentioned models VGG16 Face classifier model performs the best in the accuracy and performance metrics. So below is the implementation of the model.\n",
        "\n",
        "Dataset Link:https://drive.google.com/drive/folders/1U8rBnAsWgquWP8KVtWmOAs8nWLAoKHlr?usp=sharing"
      ],
      "metadata": {
        "id": "r-RfnGxgicHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "3MRxyDC-d3_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIrgEGeQd33j",
        "outputId": "b64bc212-689d-4b80-d68c-bbcc39e56b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "drive_root = '/content/drive/My Drive'\n",
        "os.listdir(drive_root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MXvyhVKd3qQ",
        "outputId": "3dcc5245-d350-4783-b685-7229e4697cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Watch \"Mix – Raghupati Raghav Raja Ram Lyrical Video | रघुपति राघव राजा राम | Ashit Desai | Times Music Spiritual\" on YouTube',\n",
              " 'Watch \"Mix – KO 2 - Unnai Maatrinaal Song Video | Bobby Simha | Leon James  | Elred Kumar\" on YouTube',\n",
              " 'coordination compounds.pdfnotes',\n",
              " 'coordination compds.pdf',\n",
              " 'Januvi 10 A-bio.pdf',\n",
              " 'Januvi 10 A-eco.pdf',\n",
              " 'Januvi 10 A-che.pdf',\n",
              " 'Januvi 10 A- Physics Answer.pdf',\n",
              " 'Januvi 10 A- eng.pdf',\n",
              " 'Januvi 10 A math.pdf',\n",
              " 'Januvi 10 A Soc.pdf',\n",
              " 'IMG_20200614_224449.JPG',\n",
              " 'Mr kumar.jpg',\n",
              " 'siva.jpg',\n",
              " 'sheff doc.pdf',\n",
              " 'community certi.pdf',\n",
              " 'tc sheff.pdf',\n",
              " '12th mksht.pdf',\n",
              " '10th mksht.pdf',\n",
              " 'IMG_20200808_173443.jpg',\n",
              " 'IMG_20200808_173356.jpg',\n",
              " 'IMG_20200808_173529.jpg',\n",
              " 'IMG_20200808_173502.jpg',\n",
              " 'IMG_20200808_173327.jpg',\n",
              " ' Januvi(2).pdf',\n",
              " 'tnea confirmation .pdf',\n",
              " 'sai ram.pdf',\n",
              " 'neetadmitcard .JPG',\n",
              " 'math ch3.jpg',\n",
              " '12 th marksheet.jpg',\n",
              " 'Untitled document.gdoc',\n",
              " 'IMG_20201018_141357.jpg',\n",
              " 'Sheffalee 20mis1071.pdf',\n",
              " 'aadhar card.jpg',\n",
              " 'community.jpg',\n",
              " 'APPLICATION.pdf',\n",
              " 'community januvi.jpg',\n",
              " 'Ntse2.jpg',\n",
              " 'Ntse1.jpg',\n",
              " '26c42b1c-9b45-4e02-9d13-291660851083.pdf',\n",
              " 'VOD_20210122_234205.mp4',\n",
              " 'Classroom',\n",
              " 'Document from Sheffalee.pdf',\n",
              " 'SmartSelect_20210528-200328_Instagram.jpg',\n",
              " 'STS_FROOTI',\n",
              " 'signature .pdf',\n",
              " 'Books ',\n",
              " 'Screenshot_20210804-150831_Teams.jpg',\n",
              " 'Screenshot_20210804-154554_Teams.jpg',\n",
              " 'Screenshot_20210804-154552_Teams.jpg',\n",
              " 'Screenshot_20210804-152837_Teams.jpg',\n",
              " 'SmartSelect_20210817-111942_GPay.jpg',\n",
              " 'Contact Information.gform',\n",
              " 'RSVP.gform',\n",
              " 'Party Invite.gform',\n",
              " 'Event Registration.gform',\n",
              " 'Course Evaluation.gform',\n",
              " 'Assessment.gform',\n",
              " 'sheffphoto.jpg',\n",
              " 'Colab Notebooks',\n",
              " 'RESUME SHEFFALEE',\n",
              " 'DA Sem4',\n",
              " 'receipt_for_acmegrade.pdf',\n",
              " 'School T C.pdf',\n",
              " 'hsc marksheet (1)-converted.pdf',\n",
              " 'Doc Scanner',\n",
              " 'Doc Scanner Upload',\n",
              " 'Screenshot_20220808-211450.png',\n",
              " 'ozt-cjht-pba - Oct 4, 2022.gjam',\n",
              " 'CWR-main',\n",
              " 'hotel_main_01 (1).ipynb',\n",
              " 'myj-ouyp-ngt - Nov 19, 2022 (1).gjam',\n",
              " 'myj-ouyp-ngt - Nov 19, 2022.gjam',\n",
              " 'Sheffalee - MeritCertificate.jpeg',\n",
              " 'Sivakumar resume',\n",
              " 'Scan Report ',\n",
              " 'FINGER PRINT.jpg',\n",
              " 'WhatsApp Image 2023-01-22 at 1.11.39 PM.jpeg',\n",
              " 'olist_geolocation_dataset.csv.zip',\n",
              " 'olist_order_payments_dataset.csv.zip',\n",
              " 'olist_orders_dataset.csv',\n",
              " 'olist_sellers_dataset.csv',\n",
              " 'OneDrive_1_2-2-2023.zip',\n",
              " 'product_category_name_translation.csv',\n",
              " 'ML lab work',\n",
              " 'community .jpg',\n",
              " 'Jan details ',\n",
              " 'Copy of DSA-251 By Parikh Jain.gsheet',\n",
              " 'Acknowledgement_Receipt ssn_2312949.pdf',\n",
              " 'Application_form detailsSSN_2312949.pdf',\n",
              " 'jee adv .pdf',\n",
              " '2023-07-15 14-15-46.mkv',\n",
              " 'Resume1.pdf',\n",
              " 'Sheffalee_resume (1).pdf',\n",
              " 'Sheffalee_resume.pdf',\n",
              " 'datasets']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn6wl_zTT7DU"
      },
      "outputs": [],
      "source": [
        "from keras.applications import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_rows, img_cols = 224, 224"
      ],
      "metadata": {
        "id": "5LCH8P3DUKQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16(weights = 'imagenet',\n",
        "                 include_top = False,\n",
        "                 input_shape = (img_rows, img_cols, 3))"
      ],
      "metadata": {
        "id": "eN_u8D4aUKTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Layers are set to trainable as True by default\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Let's print our layers\n",
        "for (i,layer) in enumerate(model.layers):\n",
        "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwEs67SPUKV3",
        "outputId": "30fd2aef-9889-4554-b9ae-26922a681b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 InputLayer False\n",
            "1 Conv2D False\n",
            "2 Conv2D False\n",
            "3 MaxPooling2D False\n",
            "4 Conv2D False\n",
            "5 Conv2D False\n",
            "6 MaxPooling2D False\n",
            "7 Conv2D False\n",
            "8 Conv2D False\n",
            "9 Conv2D False\n",
            "10 MaxPooling2D False\n",
            "11 Conv2D False\n",
            "12 Conv2D False\n",
            "13 Conv2D False\n",
            "14 MaxPooling2D False\n",
            "15 Conv2D False\n",
            "16 Conv2D False\n",
            "17 Conv2D False\n",
            "18 MaxPooling2D False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def add_layer(bottom_model, num_classes):\n",
        "    \"\"\"creates the top or head of the model that will be\n",
        "    placed ontop of the bottom layers\"\"\"\n",
        "\n",
        "    top_model = bottom_model.output\n",
        "    top_model = GlobalAveragePooling2D()(top_model)\n",
        "    top_model = Dense(1024,activation='relu')(top_model)\n",
        "    top_model = Dense(512,activation='relu')(top_model)\n",
        "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
        "    return top_model\n"
      ],
      "metadata": {
        "id": "J36OcHobUKX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n"
      ],
      "metadata": {
        "id": "6LMurBvdUKaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 8"
      ],
      "metadata": {
        "id": "E3enySD4UKcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FC_Head = add_layer(model, num_classes)\n",
        "\n",
        "modelnew = Model(inputs = model.input, outputs = FC_Head)\n",
        "\n",
        "print(modelnew.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4h-eKvoUKfV",
        "outputId": "9d1dce59-a9af-4297-8792-13b2dc65dd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 512)               0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              525312    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 4104      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15768904 (60.15 MB)\n",
            "Trainable params: 1054216 (4.02 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "TBBd_j9uUKh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/drive/MyDrive/datasets/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/datasets/validation'"
      ],
      "metadata": {
        "id": "6Jjlpu_hUKko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use some data augmentaiton\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=45,\n",
        "      width_shift_range=0.3,\n",
        "      height_shift_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "metadata": {
        "id": "Q8fIKmNEUKnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n"
      ],
      "metadata": {
        "id": "fMNQMr3OUKp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "S7qS4_5ZUKso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VePzli6WUKxt",
        "outputId": "6ec5ede8-aa17-45e0-984d-07e69cccd056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 673 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(img_rows, img_cols),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN5Ypdq-UKzG",
        "outputId": "4f067084-e07e-47b5-ac56-66cef77c1b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 673 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "Qr1kp-DDUK0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "checkpoint = ModelCheckpoint(\"/root/face_vgg16.h5\",\n",
        "                             monitor=\"val_loss\",\n",
        "                             mode=\"min\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)"
      ],
      "metadata": {
        "id": "MLoTVMFeUK3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop = EarlyStopping(monitor = 'val_loss',\n",
        "                          min_delta = 0,\n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True)"
      ],
      "metadata": {
        "id": "Z77w66wTUK6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [earlystop, checkpoint]"
      ],
      "metadata": {
        "id": "T3ezmDyeUK9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelnew.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = RMSprop(learning_rate = 0.001),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "BX4hL33Jeu6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_train_samples = 300\n",
        "nb_validation_samples = 100"
      ],
      "metadata": {
        "id": "buyRD3OHeu4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "JXpQYWXSeu2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelnew.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = nb_train_samples // batch_size,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = nb_validation_samples // batch_size )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3iByYNZeuxy",
        "outputId": "5cc830ac-a281-4321-e49d-84af80c944e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "18/18 [==============================] - ETA: 0s - loss: 1.2621 - accuracy: 0.5211 \n",
            "Epoch 1: val_loss did not improve from 1.24648\n",
            "18/18 [==============================] - 467s 26s/step - loss: 1.2621 - accuracy: 0.5211 - val_loss: 1.6526 - val_accuracy: 0.4375\n",
            "Epoch 2/5\n",
            "18/18 [==============================] - ETA: 0s - loss: 1.2615 - accuracy: 0.5538 \n",
            "Epoch 2: val_loss improved from 1.24648 to 0.99637, saving model to /root/face_vgg16.h5\n",
            "18/18 [==============================] - 477s 27s/step - loss: 1.2615 - accuracy: 0.5538 - val_loss: 0.9964 - val_accuracy: 0.5781\n",
            "Epoch 3/5\n",
            "18/18 [==============================] - ETA: 0s - loss: 1.1720 - accuracy: 0.5633 \n",
            "Epoch 3: val_loss improved from 0.99637 to 0.85113, saving model to /root/face_vgg16.h5\n",
            "18/18 [==============================] - 462s 26s/step - loss: 1.1720 - accuracy: 0.5633 - val_loss: 0.8511 - val_accuracy: 0.6302\n",
            "Epoch 4/5\n",
            "18/18 [==============================] - ETA: 0s - loss: 1.1679 - accuracy: 0.5835 \n",
            "Epoch 4: val_loss improved from 0.85113 to 0.80656, saving model to /root/face_vgg16.h5\n",
            "18/18 [==============================] - 461s 26s/step - loss: 1.1679 - accuracy: 0.5835 - val_loss: 0.8066 - val_accuracy: 0.6979\n",
            "Epoch 5/5\n",
            "18/18 [==============================] - ETA: 0s - loss: 1.1034 - accuracy: 0.6037 \n",
            "Epoch 5: val_loss improved from 0.80656 to 0.78324, saving model to /root/face_vgg16.h5\n",
            "18/18 [==============================] - 464s 26s/step - loss: 1.1034 - accuracy: 0.6037 - val_loss: 0.7832 - val_accuracy: 0.7031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelnew.save(\"/root/face_vgg16.h5\")"
      ],
      "metadata": {
        "id": "I_a_PSe7euvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_accuracy=history.history[\"val_accuracy\"][-1]\n",
        "print(final_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jQPL9c8eusH",
        "outputId": "459d07e5-b645-4c62-aec3-1d6eec608c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.703125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the directory where your dataset is located\n",
        "data_dir = '/content/drive/MyDrive/datasets/train'  # Replace with the path to your dataset\n",
        "\n",
        "# Create an ImageDataGenerator for the dataset\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create a generator for the dataset\n",
        "generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),  # Set the target image size\n",
        "    batch_size=32,           # Set the batch size\n",
        "    class_mode='categorical' # Set the class mode\n",
        ")\n",
        "\n",
        "# Get the class names from the generator\n",
        "class_names = list(generator.class_indices.keys())\n",
        "\n",
        "# Print the class names\n",
        "print(\"Class Names:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQCllttdrtxd",
        "outputId": "a3ff31b6-d4ff-4ec0-a021-d069693f2244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 673 images belonging to 8 classes.\n",
            "Class Names: ['Akshay Kumar', 'Alexandra Daddario', 'Alia Bhatt', 'Amitabh Bachchan', 'Andy Samberg', 'Anushka Sharma', 'Billie Eilish', 'Brad Pitt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "from keras.models import load_model\n",
        "modelnew = load_model(\"/root/face_vgg16.h5\")\n",
        "\n",
        "# Define a function to predict the class of an image\n",
        "def predict_class(model, image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255.0  # Normalize the image data if needed\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    class_index = np.argmax(prediction, axis=1)\n",
        "    return class_index[0]\n",
        "\n",
        "image_path='/content/drive/MyDrive/datasets/test/Alia Bhatt_0.jpg' #Replace with your test image filepath\n",
        "predicted_class = predict_class(modelnew, image_path)\n",
        "\n",
        "predicted_class_name = class_names[predicted_class]\n",
        "\n",
        "print(\"Predicted Class Name:\", predicted_class_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMHWQAXLn8fe",
        "outputId": "3b8bd0f7-1a47-44e6-8683-448c54b11993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 657ms/step\n",
            "Predicted Class Name: Alia Bhatt\n"
          ]
        }
      ]
    }
  ]
}