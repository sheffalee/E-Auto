{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Task 1 : Dataset Evaluation\n",
        "\n",
        "1.We scraped the web for the same number of images but are all the images useable? If you are wondering, we consider a usable image to be the front of a car with the car’s logo clearly visible. If there are images that are not usable, please remove them from the set.\n",
        "\n",
        "  Addressing the issue, I'll enhance the dataset by ensuring every image showcases a clear front view of the car with a prominent logo. This strategic improvement promises to substantially elevate image quality and usability,  aligning perfectly with the intended project goals.\n",
        "\n",
        " 2.After dataset pruning, is the dataset big enough? Is there any imbalance in our dataset?\n",
        "\n",
        " Yes, after dataset pruning, the dataset size remains substantial enough to support meaningful analysis and model training. However, an imbalance is present in the dataset, with varying quantities of usable images across different car brands or models. This imbalance could potentially impact the model's ability to generalize effectively, warranting attention to ensure representative and equitable representation.\n",
        "\n",
        " 3.Is the dataset good quality?\n",
        "\n",
        " Yes, the dataset exhibits improved quality following the pruning process, featuring clearer front views of cars with prominently displayed logos, enhancing its suitability for intended applications.\n",
        "\n",
        " Do many images require editing (cropping, zooming, sharpening, etc.)?\n",
        "\n",
        " Yes, a few number of images may require editing such as cropping, zooming, and sharpening to ensure consistency and optimal quality.\n",
        "\n",
        " Are there other issues in our dataset you can see?\n",
        "\n",
        " No, upon initial assessment, there don't appear to be any other prominent issues in the dataset.\n",
        "\n",
        " What are some challenges that you see with the current dataset?\n",
        "\n",
        " Some challenges with the current image car dataset include ensuring uniform quality through editing,and managing variations in lighting and angles that affect logo visibility.\n",
        "\n",
        "  4.Based on your evaluation, please lay out your plan for correcting any issues you’ve identified.\n",
        "\n",
        "Do you plan on manually editing some images?\n",
        "Can you do any standardization to the images?\n",
        "Is there any data augmentation you can do?\n",
        "\n",
        "   I propose implementing automated standardization techniques to ensure uniformity in cropping, resizing, and sharpening across the dataset, addressing quality issues.\n",
        " Apply rotation, flipping, and brightness adjustments to augment dataset diversity and enhance model generalization.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "30WUJcvhfkAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import os\n",
        "import base64\n",
        "from IPython.display import display, HTML\n",
        "import cv2"
      ],
      "metadata": {
        "id": "-b3SAG6RHJoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhfeugTCR-JO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Zip your dataset folder on your local machine (if not already zipped)\n",
        "dataset_folder_path = \"enter the file path\"\n",
        "zip_filename = \"dataset.zip\"\n",
        "\n",
        "# Check if the zip file already exists\n",
        "if not os.path.exists(zip_filename):\n",
        "    # Zip the dataset folder\n",
        "    !zip -r {zip_filename} \"{dataset_folder_path}\"\n",
        "\n",
        "# Define the target folder name within Colab\n",
        "colab_target_folder = 'uploaded_data'\n",
        "\n",
        "# Create the target folder if it doesn't exist\n",
        "if not os.path.exists(colab_target_folder):\n",
        "    os.makedirs(colab_target_folder)\n",
        "\n",
        "# Move the uploaded zip file to the target folder (if not already there)\n",
        "if os.path.exists(zip_filename):\n",
        "    shutil.move(zip_filename, os.path.join(colab_target_folder, zip_filename))\n",
        "\n",
        "# Upload the zip file to Colab\n",
        "files.upload()\n",
        "\n",
        "print(\"File moved to the target folder and uploaded:\", os.path.join(colab_target_folder, zip_filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ford\n",
        "# Replace with the path to your image dataset directory\n",
        "dataset_directory = r\"enter the file path\"\n",
        "\n",
        "#collect image paths\n",
        "image_paths = [os.path.join(dataset_directory, filename) for filename in os.listdir(dataset_directory)\n",
        "               if filename.lower().endswith(('.jpeg', '.png','.webp','.gif','.mpo'))]\n",
        "\n",
        "# Define the number of columns\n",
        "num_cols = 5\n",
        "\n",
        "# Generate HTML to display images in rows and columns\n",
        "html = \"<table><tr>\"\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, start=1):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Resize image for display (adjust as needed)\n",
        "        resized_image = cv2.resize(image, (200, 200))\n",
        "\n",
        "        # Convert image to base64 format for embedding in HTML\n",
        "        _, img_encoded = cv2.imencode('.png', resized_image)\n",
        "        img_base64 = base64.b64encode(img_encoded).decode('utf-8')\n",
        "\n",
        "        # Create HTML for displaying the image\n",
        "        html += f\"<td><img src='data:image/png;base64,{img_base64}'/></td>\"\n",
        "\n",
        "        # Start a new row after every 'num_cols' images\n",
        "        if idx % num_cols == 0:\n",
        "            html += \"</tr><tr>\"\n",
        "\n",
        "html += \"</tr></table>\"\n",
        "\n",
        "# Count the number of images\n",
        "num_images = len(image_paths)\n",
        "print(f\"Number of images: {num_images}\")\n",
        "# Display HTML\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "id": "fK-IcAp8jhaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Honday\n",
        "# Replace with the path to your image dataset directory\n",
        "dataset_directory = r\"enter the file path\"\n",
        "\n",
        "#collect image paths\n",
        "image_paths = [os.path.join(dataset_directory, filename) for filename in os.listdir(dataset_directory)\n",
        "               if filename.lower().endswith(('.jpeg', '.png','.webp','.gif','.mpo'))]\n",
        "\n",
        "# Define the number of columns\n",
        "num_cols = 5\n",
        "\n",
        "# Generate HTML to display images in rows and columns\n",
        "html = \"<table><tr>\"\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, start=1):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Resize image for display (adjust as needed)\n",
        "        resized_image = cv2.resize(image, (200, 200))\n",
        "\n",
        "        # Convert image to base64 format for embedding in HTML\n",
        "        _, img_encoded = cv2.imencode('.png', resized_image)\n",
        "        img_base64 = base64.b64encode(img_encoded).decode('utf-8')\n",
        "\n",
        "        # Create HTML for displaying the image\n",
        "        html += f\"<td><img src='data:image/png;base64,{img_base64}'/></td>\"\n",
        "\n",
        "        # Start a new row after every 'num_cols' images\n",
        "        if idx % num_cols == 0:\n",
        "            html += \"</tr><tr>\"\n",
        "\n",
        "html += \"</tr></table>\"\n",
        "\n",
        "# Count the number of images\n",
        "num_images = len(image_paths)\n",
        "print(f\"Number of images: {num_images}\")\n",
        "# Display HTML\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "id": "wcdq5o-vHRKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyundai\n",
        "# Replace with the path to your image dataset directory\n",
        "dataset_directory = r\"enter the file path\"\n",
        "\n",
        "#collect image paths\n",
        "image_paths = [os.path.join(dataset_directory, filename) for filename in os.listdir(dataset_directory)\n",
        "               if filename.lower().endswith(('.jpeg', '.png','.webp','.gif','.mpo'))]\n",
        "# Define the number of columns\n",
        "num_cols = 5\n",
        "\n",
        "# Generate HTML to display images in rows and columns\n",
        "html = \"<table><tr>\"\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, start=1):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Resize image for display (adjust as needed)\n",
        "        resized_image = cv2.resize(image, (200, 200))\n",
        "\n",
        "        # Convert image to base64 format for embedding in HTML\n",
        "        _, img_encoded = cv2.imencode('.png', resized_image)\n",
        "        img_base64 = base64.b64encode(img_encoded).decode('utf-8')\n",
        "\n",
        "        # Create HTML for displaying the image\n",
        "        html += f\"<td><img src='data:image/png;base64,{img_base64}'/></td>\"\n",
        "\n",
        "        # Start a new row after every 'num_cols' images\n",
        "        if idx % num_cols == 0:\n",
        "            html += \"</tr><tr>\"\n",
        "\n",
        "html += \"</tr></table>\"\n",
        "\n",
        "# Count the number of images\n",
        "num_images = len(image_paths)\n",
        "print(f\"Number of images: {num_images}\")\n",
        "\n",
        "# Display HTML\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "id": "S_UGW9jZHRG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nissan\n",
        "# Replace with the path to your image dataset directory\n",
        "dataset_directory = r\"enter the file path\"\n",
        "#collect image paths\n",
        "image_paths = [os.path.join(dataset_directory, filename) for filename in os.listdir(dataset_directory)\n",
        "               if filename.lower().endswith(('.jpeg', '.png','.webp','.gif','.mpo'))]\n",
        "# Define the number of columns\n",
        "num_cols = 5\n",
        "\n",
        "# Generate HTML to display images in rows and columns\n",
        "html = \"<table><tr>\"\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, start=1):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Resize image for display (adjust as needed)\n",
        "        resized_image = cv2.resize(image, (200, 200))\n",
        "\n",
        "        # Convert image to base64 format for embedding in HTML\n",
        "        _, img_encoded = cv2.imencode('.png', resized_image)\n",
        "        img_base64 = base64.b64encode(img_encoded).decode('utf-8')\n",
        "\n",
        "        # Create HTML for displaying the image\n",
        "        html += f\"<td><img src='data:image/png;base64,{img_base64}'/></td>\"\n",
        "\n",
        "        # Start a new row after every 'num_cols' images\n",
        "        if idx % num_cols == 0:\n",
        "            html += \"</tr><tr>\"\n",
        "\n",
        "html += \"</tr></table>\"\n",
        "\n",
        "# Count the number of images\n",
        "num_images = len(image_paths)\n",
        "print(f\"Number of images: {num_images}\")\n",
        "\n",
        "# Display HTML\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "id": "Db-2vMAvHRD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Renault\n",
        "# Replace with the path to your image dataset directory\n",
        "dataset_directory = r\"enter the file path\"\n",
        "\n",
        "#collect image paths\n",
        "image_paths = [os.path.join(dataset_directory, filename) for filename in os.listdir(dataset_directory)\n",
        "               if filename.lower().endswith(('.jpeg', '.png','.webp','.gif','.mpo'))]\n",
        "# Define the number of columns\n",
        "num_cols = 5\n",
        "\n",
        "# Generate HTML to display images in rows and columns\n",
        "html = \"<table><tr>\"\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, start=1):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Resize image for display (adjust as needed)\n",
        "        resized_image = cv2.resize(image, (200, 200))\n",
        "\n",
        "        # Convert image to base64 format for embedding in HTML\n",
        "        _, img_encoded = cv2.imencode('.png', resized_image)\n",
        "        img_base64 = base64.b64encode(img_encoded).decode('utf-8')\n",
        "\n",
        "        # Create HTML for displaying the image\n",
        "        html += f\"<td><img src='data:image/png;base64,{img_base64}'/></td>\"\n",
        "\n",
        "        # Start a new row after every 'num_cols' images\n",
        "        if idx % num_cols == 0:\n",
        "            html += \"</tr><tr>\"\n",
        "\n",
        "html += \"</tr></table>\"\n",
        "\n",
        "# Count the number of images\n",
        "num_images = len(image_paths)\n",
        "print(f\"Number of images: {num_images}\")\n",
        "# Display HTML\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "id": "GVern-S0HRBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Suzuki\n",
        "# Replace with the path to your image dataset directory\n",
        "dataset_directory = r\"enter the file path\"\n",
        "\n",
        "\n",
        "#collect image paths\n",
        "image_paths = [os.path.join(dataset_directory, filename) for filename in os.listdir(dataset_directory)\n",
        "               if filename.lower().endswith(('.jpeg', '.png','.webp','.gif','.mpo'))]\n",
        "\n",
        "# Define the number of columns\n",
        "num_cols = 5\n",
        "\n",
        "# Generate HTML to display images in rows and columns\n",
        "html = \"<table><tr>\"\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, start=1):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Resize image for display (adjust as needed)\n",
        "        resized_image = cv2.resize(image, (200, 200))\n",
        "\n",
        "        # Convert image to base64 format for embedding in HTML\n",
        "        _, img_encoded = cv2.imencode('.png', resized_image)\n",
        "        img_base64 = base64.b64encode(img_encoded).decode('utf-8')\n",
        "\n",
        "        # Create HTML for displaying the image\n",
        "        html += f\"<td><img src='data:image/png;base64,{img_base64}'/></td>\"\n",
        "\n",
        "        # Start a new row after every 'num_cols' images\n",
        "        if idx % num_cols == 0:\n",
        "            html += \"</tr><tr>\"\n",
        "\n",
        "html += \"</tr></table>\"\n",
        "\n",
        "\n",
        "# Count the number of images\n",
        "num_images = len(image_paths)\n",
        "print(f\"Number of images: {num_images}\")\n",
        "\n",
        "# Display HTML\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "id": "eVW2m2zZHQ-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tata\n",
        "# Replace with the path to your image dataset directory\n",
        "dataset_directory = r\"enter the file path\"\n",
        "\n",
        "\n",
        "#collect image paths\n",
        "image_paths = [os.path.join(dataset_directory, filename) for filename in os.listdir(dataset_directory)\n",
        "               if filename.lower().endswith(('.jpeg', '.png','.webp','.gif','.mpo'))]\n",
        "# Define the number of columns\n",
        "num_cols = 5\n",
        "\n",
        "# Generate HTML to display images in rows and columns\n",
        "html = \"<table><tr>\"\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, start=1):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Resize image for display (adjust as needed)\n",
        "        resized_image = cv2.resize(image, (200, 200))\n",
        "\n",
        "        # Convert image to base64 format for embedding in HTML\n",
        "        _, img_encoded = cv2.imencode('.png', resized_image)\n",
        "        img_base64 = base64.b64encode(img_encoded).decode('utf-8')\n",
        "\n",
        "        # Create HTML for displaying the image\n",
        "        html += f\"<td><img src='data:image/png;base64,{img_base64}'/></td>\"\n",
        "\n",
        "        # Start a new row after every 'num_cols' images\n",
        "        if idx % num_cols == 0:\n",
        "            html += \"</tr><tr>\"\n",
        "\n",
        "html += \"</tr></table>\"\n",
        "\n",
        "\n",
        "# Count the number of images\n",
        "num_images = len(image_paths)\n",
        "print(f\"Number of images: {num_images}\")\n",
        "\n",
        "\n",
        "# Display HTML\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "id": "SuyZDeIDHQ7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Toyota\n",
        "# Replace with the path to your image dataset directory\n",
        "dataset_directory = r\"enter the file path\"\n",
        "\n",
        "\n",
        "#collect image paths\n",
        "image_paths = [os.path.join(dataset_directory, filename) for filename in os.listdir(dataset_directory)\n",
        "               if filename.lower().endswith(('.jpeg', '.png','.webp','.gif','.mpo'))]\n",
        "\n",
        "# Define the number of columns\n",
        "num_cols = 5\n",
        "\n",
        "# Generate HTML to display images in rows and columns\n",
        "html = \"<table><tr>\"\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, start=1):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Resize image for display (adjust as needed)\n",
        "        resized_image = cv2.resize(image, (200, 200))\n",
        "\n",
        "        # Convert image to base64 format for embedding in HTML\n",
        "        _, img_encoded = cv2.imencode('.png', resized_image)\n",
        "        img_base64 = base64.b64encode(img_encoded).decode('utf-8')\n",
        "\n",
        "        # Create HTML for displaying the image\n",
        "        html += f\"<td><img src='data:image/png;base64,{img_base64}'/></td>\"\n",
        "\n",
        "        # Start a new row after every 'num_cols' images\n",
        "        if idx % num_cols == 0:\n",
        "            html += \"</tr><tr>\"\n",
        "\n",
        "html += \"</tr></table>\"\n",
        "\n",
        "\n",
        "# Count the number of images\n",
        "num_images = len(image_paths)\n",
        "print(f\"Number of images: {num_images}\")\n",
        "\n",
        "# Display HTML\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "id": "uf59X1wHHQ4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Volkswagen\n",
        "# Replace with the path to your image dataset directory\n",
        "dataset_directory = r\"enter the file path\"\n",
        "\n",
        "\n",
        "#collect image paths\n",
        "image_paths = [os.path.join(dataset_directory, filename) for filename in os.listdir(dataset_directory)\n",
        "               if filename.lower().endswith(('.jpeg', '.png','.webp','.gif','.mpo'))]\n",
        "\n",
        "# Define the number of columns\n",
        "num_cols = 5\n",
        "\n",
        "# Generate HTML to display images in rows and columns\n",
        "html = \"<table><tr>\"\n",
        "\n",
        "for idx, image_path in enumerate(image_paths, start=1):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is not None:\n",
        "        # Resize image for display (adjust as needed)\n",
        "        resized_image = cv2.resize(image, (200, 200))\n",
        "\n",
        "        # Convert image to base64 format for embedding in HTML\n",
        "        _, img_encoded = cv2.imencode('.png', resized_image)\n",
        "        img_base64 = base64.b64encode(img_encoded).decode('utf-8')\n",
        "\n",
        "        # Create HTML for displaying the image\n",
        "        html += f\"<td><img src='data:image/png;base64,{img_base64}'/></td>\"\n",
        "\n",
        "        # Start a new row after every 'num_cols' images\n",
        "        if idx % num_cols == 0:\n",
        "            html += \"</tr><tr>\"\n",
        "\n",
        "html += \"</tr></table>\"\n",
        "\n",
        "\n",
        "# Count the number of images\n",
        "num_images = len(image_paths)\n",
        "print(f\"Number of images: {num_images}\")\n",
        "\n",
        "# Display HTML\n",
        "display(HTML(html))\n"
      ],
      "metadata": {
        "id": "zFxRqMIzjBcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Pruning"
      ],
      "metadata": {
        "id": "aZmNqFcNgxd2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruning based on Quality assesment"
      ],
      "metadata": {
        "id": "zyqpx_yPhUfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Path to the root directory of the dataset\n",
        "dataset_root = 'enter the file path'\n",
        "\n",
        "# Threshold for quality score below which images will be pruned\n",
        "quality_threshold = 0.7\n",
        "\n",
        "# Path to the directory where pruned data will be moved\n",
        "pruned_data_dir = 'enter the file path'\n",
        "\n",
        "# Create the pruned data directory if it doesn't exist\n",
        "if not os.path.exists(pruned_data_dir):\n",
        "    os.makedirs(pruned_data_dir)\n",
        "\n",
        "# Define a function to assess image quality\n",
        "def assess_quality(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    # You can use various quality assessment methods provided by OpenCV\n",
        "    # For example, you can calculate the Structural Similarity Index (SSI) or Mean Squared Error (MSE)\n",
        "    # Return a quality score (e.g., between 0 and 1)\n",
        "    # You need to customize this function based on your specific needs\n",
        "    quality_score = calculate_quality_score(image)\n",
        "    return quality_score\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_name in os.listdir(dataset_root):\n",
        "    class_dir = os.path.join(dataset_root, class_name)\n",
        "\n",
        "    if os.path.isdir(class_dir):\n",
        "        pruned_class_dir = os.path.join(pruned_data_dir, class_name)\n",
        "        os.makedirs(pruned_class_dir, exist_ok=True)\n",
        "\n",
        "        # Iterate through images in the class folder\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image_name)\n",
        "\n",
        "            # Assess the quality of the image\n",
        "            quality_score = assess_quality(image_path)\n",
        "\n",
        "            if quality_score >= quality_threshold:\n",
        "                # Copy the image to the pruned directory\n",
        "                pruned_image_path = os.path.join(pruned_class_dir, image_name)\n",
        "                shutil.copy(image_path, pruned_image_path)\n",
        "                print(f'Kept: {image_name} (Quality: {quality_score})')\n",
        "            else:\n",
        "                print(f'Removed: {image_name} (Quality: {quality_score})')\n",
        "    else:\n",
        "        print(f'Ignored: {class_name} (not a directory)')\n",
        "\n",
        "print('Data pruning based on quality assessment complete.')\n"
      ],
      "metadata": {
        "id": "lowxPHtvHQ2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruning based on Duplicate removal"
      ],
      "metadata": {
        "id": "0kM-Xe2PhZdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "from collections import defaultdict\n",
        "import shutil\n",
        "\n",
        "# Path to the root directory of the dataset\n",
        "dataset_root = 'enter the path'\n",
        "\n",
        "# Path to the directory where pruned data will be moved\n",
        "pruned_data_dir = 'enter the path'\n",
        "\n",
        "# Create the pruned data directory if it doesn't exist\n",
        "if not os.path.exists(pruned_data_dir):\n",
        "    os.makedirs(pruned_data_dir)\n",
        "\n",
        "# Dictionary to store image hashes for duplicate detection\n",
        "image_hashes = defaultdict(list)\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_name in os.listdir(dataset_root):\n",
        "    class_dir = os.path.join(dataset_root, class_name)\n",
        "\n",
        "    if os.path.isdir(class_dir):\n",
        "        pruned_class_dir = os.path.join(pruned_data_dir, class_name)\n",
        "        os.makedirs(pruned_class_dir, exist_ok=True)\n",
        "\n",
        "        # Iterate through images in the class folder\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image_name)\n",
        "\n",
        "            # Compute the perceptual hash of the image\n",
        "            img = Image.open(image_path)\n",
        "            img_hash = imagehash.average_hash(img)\n",
        "\n",
        "            # Check if the hash is already seen (potential duplicate)\n",
        "            if img_hash in image_hashes:\n",
        "                duplicates = image_hashes[img_hash]\n",
        "                for duplicate in duplicates:\n",
        "                    # Compare the current image with each duplicate\n",
        "                    # You can use hash similarity thresholds for comparison\n",
        "                    similarity_threshold = 10  # Adjust as needed\n",
        "                    if img_hash - duplicate < similarity_threshold:\n",
        "                        print(f'Removed duplicate: {image_name}')\n",
        "                        break  # Don't copy this image, as it's a duplicate\n",
        "                else:\n",
        "                    # No similar duplicates found, copy the image\n",
        "                    pruned_image_path = os.path.join(pruned_class_dir, image_name)\n",
        "                    shutil.copy(image_path, pruned_image_path)\n",
        "                    image_hashes[img_hash].append(img_hash)\n",
        "            else:\n",
        "                # First image with this hash, copy it\n",
        "                pruned_image_path = os.path.join(pruned_class_dir, image_name)\n",
        "                shutil.copy(image_path, pruned_image_path)\n",
        "                image_hashes[img_hash].append(img_hash)\n",
        "    else:\n",
        "        print(f'Ignored: {class_name} (not a directory)')\n",
        "\n",
        "print('Duplicate removal and dataset pruning complete.')\n"
      ],
      "metadata": {
        "id": "H8lX9CECHQzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruning based on Spatial or temporal pruning"
      ],
      "metadata": {
        "id": "9go10sRmhjBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "\n",
        "# Path to the root directory of the dataset\n",
        "dataset_root = 'enter the path'\n",
        "\n",
        "# Path to the directory where pruned data will be moved\n",
        "pruned_data_dir = 'enter the path'\n",
        "\n",
        "# Create the pruned data directory if it doesn't exist\n",
        "if not os.path.exists(pruned_data_dir):\n",
        "    os.makedirs(pruned_data_dir)\n",
        "\n",
        "# Path to pre-trained car detection model XML file (Cascade Classifier)\n",
        "car_cascade_path = 'enter the file path'  # Provide the correct path\n",
        "\n",
        "# Load the car detection model\n",
        "car_cascade = cv2.CascadeClassifier(car_cascade_path)\n",
        "\n",
        "# Function to extract front views of cars\n",
        "def extract_front_view(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    cars = car_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    front_views = []\n",
        "    for (x, y, w, h) in cars:\n",
        "        front_view = img[y:y+h, x:x+w]\n",
        "        front_views.append(front_view)\n",
        "\n",
        "    return front_views\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_name in os.listdir(dataset_root):\n",
        "    class_dir = os.path.join(dataset_root, class_name)\n",
        "\n",
        "    if os.path.isdir(class_dir):\n",
        "        pruned_class_dir = os.path.join(pruned_data_dir, class_name)\n",
        "        os.makedirs(pruned_class_dir, exist_ok=True)\n",
        "\n",
        "        # Iterate through images in the class folder\n",
        "        for image_name in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, image_name)\n",
        "\n",
        "            # Extract front views of cars\n",
        "            front_views = extract_front_view(image_path)\n",
        "\n",
        "            for idx, front_view in enumerate(front_views):\n",
        "                # Save the front view image to the pruned directory\n",
        "                pruned_image_path = os.path.join(pruned_class_dir, f'{image_name}_front{idx}.jpg')\n",
        "                cv2.imwrite(pruned_image_path, front_view)\n",
        "                print(f'Extracted front view from: {image_name}')\n",
        "    else:\n",
        "        print(f'Ignored: {class_name} (not a directory)')\n",
        "\n",
        "print('Spatial pruning for front views complete.')\n"
      ],
      "metadata": {
        "id": "bETJCgiQHQw9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}